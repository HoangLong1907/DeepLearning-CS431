{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    },
    "colab": {
      "name": "word2vec_tutorial.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HoangLong1907/DeepLearning-CS431/blob/main/Baitap/word2vec_tutorial.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C-B0p2tQUrIR"
      },
      "source": [
        "Để chạy được tutorial này, chúng ta cần phải cài đặt thư viện GenSim.\n",
        "Để cài bằng Anaconda ta sử dụng lệnh sau:\n",
        "\n",
        "$ conda install -c anaconda gensim\n",
        "\n",
        "Sau đó import các thư viện cần thiết như sau:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QcVWDot5OMQX",
        "outputId": "40159935-e643-473c-b086-39dc5f5791f3"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZUG2jp88UrIX"
      },
      "source": [
        "from gensim.models import KeyedVectors\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d7qEm6KnUrIa"
      },
      "source": [
        "# Load model\n",
        "Trước hết, ta cần tải model về theo đường dẫn sau:https://s3-us-west-1.amazonaws.com/fasttext-vectors/wiki-news-300d-1M.vec.zip\n",
        "\n",
        "Chi tiết có thể tham khảo trên trang FastText https://fasttext.cc/docs/en/english-vectors.html. Đối với các ngôn ngữ khác, trong đó có tiếng Việt ta có thể tải về từ đây:\n",
        "https://fasttext.cc/docs/en/crawl-vectors.html\n",
        "\n",
        "Thời gian load mô hình đã huấn luyện này có thể mất từ 5-10 phút )-:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xd0105cIUrIb"
      },
      "source": [
        "word_vectors = KeyedVectors.load_word2vec_format('/content/drive/MyDrive/DeepLearning/wiki-news-300d-1M.vec', binary=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "22Dxu1kBUrIb"
      },
      "source": [
        "# Word embeding: biểu diễn một từ dưới dạng một vector"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sCv6Ffu5UrIb",
        "outputId": "117c4e36-7d28-49af-8260-7980ef2a315c"
      },
      "source": [
        "woman_vec = word_vectors['woman']\n",
        "print('Feature representation of `woman` is:', woman_vec)\n",
        "print('Size of feature representation: ', woman_vec.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Feature representation of `woman` is: [ 7.510e-02 -5.910e-02 -1.020e-02 -4.900e-03 -2.230e-02  1.397e-01\n",
            "  1.970e-02  1.058e-01 -6.740e-02  1.333e-01  8.540e-02  6.220e-02\n",
            "  1.250e-01  8.060e-02  3.700e-03  2.580e-02  7.560e-02  8.550e-02\n",
            " -2.720e-02 -3.470e-02 -1.167e-01 -1.000e-04 -1.724e-01 -1.090e-02\n",
            "  1.630e-02 -1.140e-02 -3.550e-02  1.869e-01  4.630e-02 -2.070e-02\n",
            "  6.830e-02  3.230e-02  6.040e-02  1.790e-02 -5.800e-02 -3.860e-02\n",
            "  1.900e-02  1.340e-01  1.246e-01  3.190e-02  1.430e-01 -3.370e-02\n",
            "  6.510e-02 -1.368e-01 -6.050e-02 -5.230e-02  3.340e-02  6.600e-02\n",
            " -8.400e-03 -7.990e-02  1.318e-01 -6.720e-02 -6.142e-01  4.300e-03\n",
            "  1.470e-02 -6.630e-02  3.920e-02  4.680e-02  9.020e-02 -2.040e-02\n",
            " -5.600e-03 -3.260e-02  5.350e-02 -8.250e-02 -5.250e-02 -2.490e-02\n",
            "  1.021e-01  1.045e-01  1.810e-02 -5.670e-02 -6.390e-02 -1.349e-01\n",
            " -9.700e-03  1.113e-01 -1.544e-01  8.390e-02  1.040e-02 -5.720e-02\n",
            "  4.600e-03  1.834e-01  1.060e-02  1.630e-01  8.160e-02 -2.479e-01\n",
            "  9.800e-03  2.720e-02 -4.950e-02 -4.300e-03  1.321e-01 -9.070e-02\n",
            " -6.810e-02 -9.260e-02  1.076e-01  2.200e-03 -3.180e-02 -7.700e-02\n",
            "  1.280e-02  5.260e-02 -1.223e-01  1.133e-01 -1.384e-01 -1.060e-02\n",
            " -1.250e-01 -1.021e-01 -1.162e-01  1.090e-02  3.080e-02  2.060e-02\n",
            " -7.590e-02  6.210e-02 -1.930e-02  1.633e-01  9.450e-02 -9.500e-03\n",
            " -6.030e-02 -1.916e-01 -2.233e-01 -1.966e-01 -1.125e-01 -3.912e-01\n",
            "  4.490e-02  1.398e-01  2.890e-02 -1.107e-01  1.183e-01  1.737e-01\n",
            " -5.590e-02  2.390e-02 -2.820e-02 -8.840e-02 -8.330e-02  1.785e-01\n",
            " -6.600e-02 -6.060e-02 -1.181e-01  6.040e-02 -2.040e-02  2.119e-01\n",
            "  2.420e-02 -2.750e-02 -5.190e-02 -3.350e-02 -1.600e-02  1.765e-01\n",
            "  2.000e-04  8.400e-03 -6.390e-02  2.420e-02  5.940e-02 -7.370e-02\n",
            " -6.240e-02 -1.527e-01 -8.290e-02 -1.557e-01 -8.960e-02  5.320e-02\n",
            "  9.130e-02  1.233e-01  1.361e-01  4.160e-02 -7.090e-02  4.090e-02\n",
            "  1.546e-01 -3.730e-02 -6.220e-02  9.000e-02 -1.050e-02  7.850e-02\n",
            " -8.600e-03 -9.240e-02 -1.008e-01 -2.620e-02 -6.190e-02  6.170e-02\n",
            "  3.002e-01 -7.550e-02  2.803e-01  7.250e-02 -1.268e-01  7.510e-02\n",
            "  3.670e-02  7.460e-02  3.530e-02  8.800e-02 -5.820e-02 -1.740e-02\n",
            "  3.100e-03 -7.630e-02 -2.563e-01 -1.089e-01  1.132e-01 -1.107e-01\n",
            " -4.760e-02  1.569e-01 -1.690e-02  3.600e-02 -1.085e-01 -2.530e-02\n",
            "  1.201e-01  7.300e-03 -8.850e-02  2.630e-02 -2.490e-02 -7.530e-02\n",
            "  8.480e-02  6.180e-02  5.180e-02 -3.530e-01  2.000e-02 -1.100e-02\n",
            "  8.030e-02 -1.540e-02  1.256e-01 -1.499e-01  4.180e-02  6.610e-02\n",
            "  2.010e-02 -2.910e-02 -5.170e-02  7.760e-02 -7.250e-02  5.830e-02\n",
            " -9.300e-03  1.880e-02 -4.360e-02 -6.170e-02  1.121e-01  9.070e-02\n",
            " -6.580e-02 -7.480e-02 -2.800e-03  4.440e-02  3.881e-01 -7.430e-02\n",
            " -2.000e-02 -6.010e-02 -1.270e-02  6.570e-02 -2.553e-01 -3.700e-02\n",
            " -9.320e-02  1.340e-02  1.408e-01  1.410e-02  2.400e-02  1.083e-01\n",
            " -4.530e-02 -1.410e-02 -1.891e-01  3.559e-01  1.660e-01  1.850e-02\n",
            "  1.240e-02  1.870e-02  1.751e-01  2.390e-02 -6.300e-03  5.760e-02\n",
            "  8.170e-02 -2.440e-01 -7.200e-03  1.018e-01  5.920e-02 -3.020e-02\n",
            " -5.859e-01 -7.240e-02 -4.970e-02  9.550e-02 -1.939e-01 -1.970e-02\n",
            " -7.200e-02  5.850e-02  2.840e-02  1.563e-01  8.940e-02  1.372e-01\n",
            "  7.200e-02 -9.350e-02 -4.690e-02  6.930e-02  1.400e-02  1.558e-01\n",
            "  1.410e-02  3.890e-02 -5.000e-03  1.061e-01 -3.380e-02 -2.055e-01\n",
            " -3.380e-02  5.260e-02  3.420e-02 -1.571e-01 -6.320e-02 -8.500e-03\n",
            "  2.689e-01  1.425e-01 -3.350e-02  5.010e-02  1.330e-01  3.520e-02]\n",
            "Size of feature representation:  (300,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rsjrV04LUrIc"
      },
      "source": [
        "# Tính độ tương đồng giữa hai từ\n",
        "Mức độ tương đồng ở đây là tổng thể từ loại, cách sử dụng từ và vai trò trong câu.\n",
        "Do đó, đừng bất ngờ khi độ tương đồng của 'woman' và 'man' lại cao hơn 'woman' và 'girl'.\n",
        "Vai trò, chức năng của 'woman' và 'man' trong câu thường có tính đối ngẫu gần giống nhau. Trong khi 'woman' và 'girl' thì không đối ngẫu, do 'girl' là một tập con của 'woman' nên trong cấu trúc câu từ 'girl' đôi khi không thể thay thế bằng 'woman' được."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fSRt1AijUrIc",
        "outputId": "291d61bd-67ab-4faf-d0f1-d3f9374d5640"
      },
      "source": [
        "print('Similarity of `woman` and `man`:', word_vectors.similarity('woman', 'man'))\n",
        "print('Similarity of `woman` and `man`:', word_vectors.similarity('woman', 'girl'))\n",
        "print('Similarity of `boy` and `man`:', word_vectors.similarity('boy', 'girl'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Similarity of `woman` and `man`: 0.81645226\n",
            "Similarity of `woman` and `man`: 0.744082\n",
            "Similarity of `boy` and `man`: 0.8618077\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "35-4G70FUrIc"
      },
      "source": [
        "# Mối quan hệ về không gian giữa các từ\n",
        "\n",
        "Câu hỏi: Nếu như 'king' là 'man' thì 'queen' là gì?\n",
        "\n",
        "Trong không gian vector để biểu diễn các từ, vị trí tương đối giữa các cặp từ có mối quan hệ tương đồng về ngữ nghĩa thì sẽ có khoảng cách tương đối giống nhau. Hình sau minh hoạ mối quan hệ về mặt không gian (vector) giữa các từ. Ta dự đoán rằng các vector biểu diễn này sẽ có sự tương đồng trong không gian, nghĩa là để trả lời câu hỏi trên, ta phải giải phương trình thể hiện mối quan hệ trong không gian như sau: \n",
        "\n",
        "vector('king') - vector('queen') = vector('man') - vector(X)\n",
        "\n",
        "Suy ra: vector(X) = vector('man') - vector('king') + vector('queen').\n",
        "\n",
        "Như vậy ta sẽ xác định xem những từ nào gần với phép biến đổi trên:\n",
        "![title](king_and_queen.png)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ymTQHNtUUrId",
        "outputId": "9db4d199-023c-4be9-9a12-ba2aa94d27c9"
      },
      "source": [
        "sim_words = word_vectors.most_similar_cosmul(positive=['Vietnam', 'pho'], negative=['wolrd'])\n",
        "print(sim_words[0][0])\n",
        "sim_words"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Vietnamese\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('Vietnamese', 1.0888371467590332),\n",
              " ('Pho', 1.077613353729248),\n",
              " ('Nguyen', 1.0310759544372559),\n",
              " ('Huynh', 1.0143067836761475),\n",
              " ('Hanoi', 1.0122424364089966),\n",
              " ('Saigon', 1.006687045097351),\n",
              " ('Dinh', 1.0029217004776),\n",
              " ('Vuong', 1.0000678300857544),\n",
              " ('Viet', 0.9949368834495544),\n",
              " ('Danang', 0.9907997250556946)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vp_AAFaFUrId"
      },
      "source": [
        "Như vậy, về mặt không gian vector, ta có thể biểu diễn được mối quan hệ ngữ nghĩa của các từ một cách đáng ngạc nhiên. Quan hệ trên là: Người đứng đầu - Giới tính.\n",
        "\n",
        "Hoàn toàn tương tự, ta có thể khai thác được các mối quan hệ ngữ nghĩa khác như: Đất nước - Thủ Đô, Đất nước - món ăn, Công ty - Sản phẩm, Đất nước - Tổng thống. Ví dụ dưới đây minh hoạ cho mối quan hệ ngữ nghĩa: Đất nước - Thủ đô."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j7l_OOMHUrId",
        "outputId": "2413f6be-f573-4566-a330-f72de90afb5f"
      },
      "source": [
        "sim_words = word_vectors.most_similar_cosmul(positive=['Vietnam', 'Berlin'], negative=['Germany'])\n",
        "print('If Berlin is the capital of Germany then', sim_words[0][0], 'is the capital of Vietnam')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "If Berlin is the capital of Germany then Hanoi is the capital of Vietnam\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "As64AYnIUrIe"
      },
      "source": [
        "# Thử nghiệm\n",
        "Các bạn hãy thử trên các quan hệ khác như: Đất nước - món ăn, Công ty - Sản phẩm, Đất nước - Tổng thống, Bang - Thành phố."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vIMeEDfoBh9m"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}